{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4.2\n",
    "\n",
    "Вихляев Егор, ММТ-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Предварительный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Данные содержат следующие характеристики:\n",
    "\n",
    "Pregnancies – число случаев беременности\n",
    "\n",
    "Glucose – концентрация глюкозы в крови\n",
    "\n",
    "BloodPressure – артериальное диастолическое давление (мм рт. ст.)\n",
    "\n",
    "SkinThickness – толщина кожной складки трехглавой мышцы (мм)\n",
    "\n",
    "Insulin – 2-х часовой сывороточный инсулин\n",
    "\n",
    "BMI – индекс массы тела\n",
    "\n",
    "DiabetesPedigreeFunction – числовой параметр наследственности диабета\n",
    "\n",
    "Age – возраст\n",
    "\n",
    "Outcome – целевая переменная: 1 – наличие заболевания, 0 – отсутствие\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Распределение наблюдений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI   DiabetesPedigreeFunction  Age\n",
       "0        0            57       60             0              0        21.7  0.735                     67     1\n",
       "                      67       76             0              0        45.3  0.194                     46     1\n",
       "         12           100      84             33             105      30.0  0.488                     46     1\n",
       "         10           133      68             0              0        27.0  0.245                     36     1\n",
       "                      139      80             0              0        27.1  1.441                     57     1\n",
       "                                                                                                            ..\n",
       "1        5            116      74             29             0        32.3  0.660                     35     1\n",
       "                      124      74             0              0        34.0  0.220                     38     1\n",
       "                      130      82             0              0        39.1  0.956                     37     1\n",
       "                      136      84             41             88       35.0  0.286                     35     1\n",
       "         17           163      72             41             114      40.9  0.817                     47     1\n",
       "Name: count, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Outcome').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество наблюдений в каждом классе:\n",
      " Outcome\n",
      "0    500\n",
      "1    268\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_dist = df.groupby('Outcome').size()\n",
    "print('Количество наблюдений в каждом классе:\\n', class_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, наблюдения распределились неравномерно. Класс «0» явно превосходит класс «1» примерно в 1.8 раз. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Разделение данных на признаки и ответы, а затем на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объект X:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  \n",
      "0                     0.627   50  \n",
      "1                     0.351   31  \n",
      "2                     0.672   32  \n",
      "3                     0.167   21  \n",
      "4                     2.288   33  \n",
      "Объект y:\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: Outcome, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df[['Pregnancies',  'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']] #Признаки\n",
    "y = df['Outcome'] #Целевая переменная (ответы)\n",
    "\n",
    "print('Объект X:')\n",
    "print(X.head())\n",
    "\n",
    "print('Объект y:')\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающего набора данных (X_train): (691, 8)\n",
      "Размер тестового набора данных (X_test): (77, 8)\n",
      "Размер обучающего набора данных (y_train): (691,)\n",
      "Размер тестового набора данных (y_test): (77,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "print('Размер обучающего набора данных (X_train):', X_train.shape)\n",
    "print('Размер тестового набора данных (X_test):', X_test.shape)\n",
    "print('Размер обучающего набора данных (y_train):', y_train.shape)\n",
    "print('Размер тестового набора данных (y_test):', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение модели логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Непосредственно обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Выведем веса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса модели:\n",
      "Pregnancies: 0.15\n",
      "Glucose: 0.03\n",
      "BloodPressure: -0.01\n",
      "SkinThickness: -0.0\n",
      "Insulin: -0.0\n",
      "BMI: 0.07\n",
      "DiabetesPedigreeFunction: 1.06\n",
      "Age: 0.0\n"
     ]
    }
   ],
   "source": [
    "coeffs = lr_model.coef_\n",
    "\n",
    "print('Веса модели:')\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{col}: {round(coeffs[0][i],2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Оцениваем качество модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86        53\n",
      "           1       0.71      0.62      0.67        24\n",
      "\n",
      "    accuracy                           0.81        77\n",
      "   macro avg       0.78      0.76      0.76        77\n",
      "weighted avg       0.80      0.81      0.80        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print('Classification report:', class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что поскольку у нас сильный дисбаланс в классах, то $f1-score$ не рассчитывается, ибо предсказывается только наиболее распространенный класс. $f1$ же рассчитывается только для классов, которые присутствуют как в истинных метках, так и в предсказанных.\n",
    "\n",
    "Точность (Precision):\n",
    "\n",
    "1. Для класса 0 точность составляет 0.84, что означает, что 84% объектов, предсказанных как класс 0, действительно принадлежат к классу 0.\n",
    "2. Для класса 1 точность составляет 0.71, что означает, что 71% объектов, предсказанных как класс 1, действительно принадлежат к классу 1.\n",
    "\n",
    "Полнота (Recall):\n",
    "\n",
    "1. Для класса 0 полнота составляет 0.89, что означает, что 89% объектов класса 0 было правильно обнаружено моделью.\n",
    "2. Для класса 1 полнота составляет 0.62, что означает, что только 62% объектов класса 1 было обнаружено моделью.\n",
    "\n",
    "Accuracy (точность): \n",
    "\n",
    "- 0.81 - доля правильно классифицированных объектов от общего числа объектов.\n",
    "\n",
    "Macro avg (макро-усреднение): \n",
    "\n",
    "- среднее значение метрик для всех классов без учета их распределения в данных.\n",
    "\n",
    "Weighted avg (взвешенное усреднение): \n",
    "\n",
    "- взвешенное среднее значение метрик для всех классов, пропорционально их поддержке в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Обучим модель на стандартизированных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация данных признаковых переменных часто требуется в методах машинного обучения, особенно в алгоритмах, которые чувствительны к масштабу признаков, таких как метод ближайших соседей (k-Nearest Neighbors), метод опорных векторов (Support Vector Machines) или градиентный спуск.\n",
    "\n",
    "Вот несколько случаев, когда нормализация данных может быть полезной:\n",
    "\n",
    "1. Методы, основанные на расстоянии: Алгоритмы, которые используют расстояния между точками данных, такие как k-Nearest Neighbors, могут быть сильно повлияны на масштаб признаков. Если один из признаков имеет гораздо больший масштаб, чем другие, это может привести к тому, что расстояние будет определяться главным образом этим признаком.\n",
    "\n",
    "2. Градиентный спуск: В алгоритмах оптимизации, таких как градиентный спуск, масштаб признаков может влиять на скорость сходимости. Нормализация признаков может помочь ускорить сходимость алгоритма.\n",
    "\n",
    "3. Регуляризация: Некоторые алгоритмы машинного обучения, такие как регрессия Ridge или Lasso, могут быть чувствительны к масштабу признаков. Нормализация данных может помочь в справлении с этой проблемой.\n",
    "\n",
    "Для модели логистической регрессии нормализация данных обычно не является обязательной, но может быть полезной в некоторых случаях.\n",
    "\n",
    "Вот несколько соображений:\n",
    "\n",
    "1. Масштабирование признаков: Логистическая регрессия не является алгоритмом, основанным на расстояниях, как, например, k-Nearest Neighbors. Однако масштабирование признаков может улучшить процесс обучения модели, ускорить сходимость и помочь в интерпретации коэффициентов.\n",
    "\n",
    "2. Регуляризация: Если вы используете регуляризацию, такую как L1 (Lasso) или L2 (Ridge), масштабирование признаков может быть полезным. Это может помочь в том, чтобы штраф за коэффициенты признаков был более справедливым и однородным по всем признакам.\n",
    "\n",
    "3. Интерпретация коэффициентов: Если вы хотите сравнивать важность признаков на основе их коэффициентов в модели, масштабирование может помочь сделать эти сравнения более справедливыми.\n",
    "\n",
    "Таким образом, хотя нормализация данных не является обязательной для построения модели логистической регрессии, ее применение может быть полезным для улучшения производительности модели и упрощения интерпретации результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model_scaled = LogisticRegression()\n",
    "lr_model_scaled.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса модели:\n",
      "Pregnancies: 0.15\n",
      "Glucose: 0.03\n",
      "BloodPressure: -0.01\n",
      "SkinThickness: -0.0\n",
      "Insulin: -0.0\n",
      "BMI: 0.07\n",
      "DiabetesPedigreeFunction: 1.06\n",
      "Age: 0.0\n"
     ]
    }
   ],
   "source": [
    "coeffs_scaled = lr_model_scaled.coef_\n",
    "\n",
    "print('Веса модели:')\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{col}: {round(coeffs[0][i],2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87        53\n",
      "           1       0.75      0.62      0.68        24\n",
      "\n",
      "    accuracy                           0.82        77\n",
      "   macro avg       0.80      0.77      0.78        77\n",
      "weighted avg       0.81      0.82      0.81        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_scaled = lr_model_scaled.predict(X_test_scaled)\n",
    "class_report_scaled = classification_report(y_test, y_pred_scaled)\n",
    "print('Classification report:', class_report_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность (Precision):\n",
    "\n",
    "1. Для класса 0 точность составляет 0.84, что означает, что 84% объектов, предсказанных как класс 0, действительно принадлежат к классу 0. Это также, как и в предыдущем отчете.\n",
    "2. Для класса 1 точность составляет 0.75, что также выше, чем в предыдущем отчете (0.71).\n",
    "\n",
    "Полнота (Recall):\n",
    "\n",
    "1. Для класса 0 полнота составляет 0.91, что выше, чем в предыдущем отчете (0.89).\n",
    "2. Для класса 1 полнота составляет 0.62, что также также та же самая, как и в предыдущем отчете (0.62).\n",
    "\n",
    "F1-мера (F1-score):\n",
    "\n",
    "1. F1-мера для класса 0 составляет 0.87, что выше, чем в предыдущем отчете (0.86).\n",
    "2. F1-мера для класса 1 составляет 0.68, что также выше, чем в предыдущем отчете (0.67).\n",
    "\n",
    "Поддержка (Support):\n",
    "\n",
    "1. Поддержка для каждого класса осталась той же самой.\n",
    "2. Также в отчете представлены общие метрики для всех классов:\n",
    "\n",
    "Accuracy (точность): \n",
    "\n",
    "- 0.82 - повышение точности на 1% по сравнению с предыдущими результатами.\n",
    "\n",
    "Macro avg (макро-усреднение): \n",
    "\n",
    "- значение F1-меры немного повысилось до 0.78.\n",
    "\n",
    "Weighted avg (взвешенное усреднение): \n",
    "- взвешенное среднее значение метрик также немного повысилось до 0.81.\n",
    "\n",
    "##### Вывод: модель показывает небольшое улучшение!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Кросс-валидация (cross-validation)** - это метод оценки производительности модели машинного обучения, который позволяет оценить, насколько хорошо модель обобщает свои предсказательные способности на новых данных. Он представляет собой процедуру, при которой исходный набор данных разбивается на несколько подмножеств (называемых фолдами), после чего модель обучается на одном из фолдов и тестируется на оставшихся фолдах. Этот процесс повторяется несколько раз, и для каждого фолда вычисляется метрика производительности (например, точность, $F1$-мера или $ROC AUC$). Затем эти метрики усредняются для получения итоговой оценки качества модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_lr_model = cross_val_score(lr_model, X_train, y_train, cv=5)\n",
    "scores_lr_model_scaled = cross_val_score(lr_model_scaled, X_train_scaled, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cv** — это количество фолдов.\n",
    "\n",
    "Более высокое количество фолдов может привести к более надежной оценке производительности модели, поскольку каждый фолд будет содержать меньше данных, и модель будет оцениваться на большем числе различных подмножеств данных.\n",
    "\n",
    "Меньшее количество фолдов может привести к более быстрой оценке производительности модели, особенно на больших наборах данных или для моделей, требующих длительного времени обучения.\n",
    "\n",
    "Общее правило заключается в том, что нужно выбирать количество фолдов таким образом, чтобы балансировать между надежностью оценки и вычислительной нагрузкой. Обычно на практике используются значения от 3 до 10 для количества фолдов в перекрестной проверке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность модели lr_model без стандартизации на перекрестной проверке: 0.75\n",
      "Средняя точность модели lr_model_scaled с использованием стандартизации на перекрестной проверке: 0.77\n"
     ]
    }
   ],
   "source": [
    "print(\"Средняя точность модели lr_model без стандартизации на перекрестной проверке:\", round(scores_lr_model.mean(),2))\n",
    "print(\"Средняя точность модели lr_model_scaled с использованием стандартизации на перекрестной проверке:\", round(scores_lr_model_scaled.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Вывод: Средняя точность модели lr_model_scaled с использованием стандартизации (0.77) выше, чем у модели lr_model без стандартизации (0.75). Это указывает на то, что стандартизация признаков может улучшить производительность модели логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Поиск по сетке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Поиск по сетке (grid search)** - это метод поиска оптимальных гиперпараметров* для модели машинного обучения путем систематического перебора значений гиперпараметров из определенного набора. Для модели логистической регрессии гиперпараметры могут включать в себя коэффициент регуляризации (например, параметр C в логистической регрессии), тип регуляризации (L1 или L2) и другие параметры, которые могут влиять на процесс обучения модели.\n",
    "\n",
    "Когда говорят о \"качестве модели при нестандартизированных и для стандартизированных признаков почти равном\", это может означать, что стандартизация признаков (например, масштабирование) не сильно влияет на результат модели. Однако, это не означает, что оптимальные значения гиперпараметров будут такими же для стандартизированных и нестандартизированных признаков.\n",
    "\n",
    "Поэтому поиск по сетке может быть полезным для определения оптимальных гиперпараметров в обоих случаях. При этом вам необходимо будет определить набор значений гиперпараметров, которые вы хотите исследовать, а затем применить кросс-валидацию для каждой комбинации значений гиперпараметров, чтобы оценить их производительность на ваших данных. После этого вы можете выбрать комбинацию гиперпараметров, которая дает наилучшее качество модели.\n",
    "\n",
    "В нашем случае, точности моделей при стандартизированных и нестандартизированных данных практически идентичны (0.75 и 0.77 соответственно). Это говорит о том, что модель логистической регрессии не чувствительна к масштабированию признаков. **В таком случае, поиск по сетке можно произвести для любой из этих моделей, поскольку результат будет примерно схожим. Но обычно рекомендуется использовать стандартизированные данные, поскольку это сделает процесс более стабильным и улучшит интепретируемость весов модели.** \n",
    "\n",
    "-----------\n",
    "\n",
    "*: **Гиперпараметры** - это параметры, которые не учатся непосредственно во время обучения модели, а задаются вручную до начала процесса обучения и влияют на его ход и результат. Например, для модели логистической регрессии гиперпараметрами могут быть коэффициент регуляризации, тип регуляризации (L1 или L2), порог для принятия решения и так далее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'C': 10, 'penalty': 'l2'}\n",
      "Лучшая оценка: 0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Определяем сетку гиперпарамметров\n",
    "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l2']}\n",
    "\n",
    "#Создаем экземпляр класса GridSearchCV:\n",
    "grid_search = GridSearchCV(lr_model_scaled, param_grid, cv=5, scoring='f1') #cv -- количество фолдов; scoring, очевидно, -- метрика\n",
    "\n",
    "#Выполняем поиск по сетке\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Получаем лучшие параметры и оценку\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "#Дополнительно оценим модель на тестовых данных\n",
    "test_score = grid_search.score(X_test_scaled, y_test)\n",
    "\n",
    "print('Лучшие параметры:', best_params)\n",
    "print('Лучшая оценка:', round(best_score,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку наши классы изначально несбалансированы, то было разумным в качестве scoring использовать именно $f1$-меру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Метод опорных векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод опорных векторов** — это мощный алгоритм машинного обучения, который используется как для классификации, так и для регрессии. Он строит гиперплоскости в пространстве признаков, которые лучше всего разделяют точки данных разных классов. Алгоритм работает над предположении, что чем больше расстояние (зазор) между разделяющей гиперплоскостью и объектами разделяемых классов, тем меньше будет средняя ошибка классификатора.\n",
    "\n",
    "Гиперплоскость всегда имеет размерность на 1 меньше, чем пространство признаков. Например, для $\\mathbb{R}^1$ гиперплоскостью является точка, для $\\mathbb{R}^2$ — прямая, для $\\mathbb{R}^3$ — плоскость и т.д. Гиперплоскость делит пространство на два полупространства. Говорят, что она разделяет два класса $C_1$ и $C_2$, если объекты этих классов лежат по разные стороны от гиперплоскости.\n",
    "\n",
    "Сама гиперплоскость в пространстве $\\mathbb{R}^n$ определяется уравнением $\\langle \\vec{w}, \\vec{x} \\rangle - b = 0$ при заданных $\\vec{w}$ и $b$ — как множество векторов $\\vec{x} = (x_1, \\ ... \\, x_n) \\in \\mathbb{R}^{n-1}$.\n",
    "\n",
    "Ключевые преимущества SVM включают в себя:\n",
    "\n",
    "1. Эффективность в пространствах высокой размерности.\n",
    "2. Устойчивость к переобучению, особенно в случае небольшого количества обучающих данных.\n",
    "3. Возможность использования различных ядерных функций для адаптации к нелинейным данным.\n",
    "\n",
    "Однако, SVM также имеет недостатки, включая:\n",
    "\n",
    "1. Сложность настройки гиперпараметров, таких как выбор ядра и параметра регуляризации.\n",
    "2. Требование к масштабированию данных.\n",
    "3. Относительно плохая производительность на больших наборах данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Обучим SVM-модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Оценим качество SVM-модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85        53\n",
      "           1       0.70      0.58      0.64        24\n",
      "\n",
      "    accuracy                           0.79        77\n",
      "   macro avg       0.76      0.74      0.75        77\n",
      "weighted avg       0.79      0.79      0.79        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print('Classification report:\\n', classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из этого отчета, можно сказать, что модель хорошо справляется с классификацией примеров класса 0 (высокая точность и полнота), но у нее есть проблемы с классификацией примеров класса 1 (низкая полнота)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Построим SVM-модель на стандартизированных данных и оценим ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.86        53\n",
      "           1       0.74      0.58      0.65        24\n",
      "\n",
      "    accuracy                           0.81        77\n",
      "   macro avg       0.78      0.74      0.76        77\n",
      "weighted avg       0.80      0.81      0.80        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model_scaled = SVC(kernel='linear', random_state=42)\n",
    "svm_model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_svm_scaled = svm_model_scaled.predict(X_test_scaled)\n",
    "print('Classification report:\\n', classification_report(y_test, y_pred_svm_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что модель улучшилась во всех оценках, кроме macroavg/recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Оценим SVM-модель через кросс-валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svm_model = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
    "scores_svm_model_scaled = cross_val_score(svm_model_scaled, X_train_scaled, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность модели svm_model без стандартизации на перекрестной проверке: 0.76\n",
      "Средняя точность модели svm_model_scaled с использованием стандартизации на перекрестной проверке: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Средняя точность модели svm_model без стандартизации на перекрестной проверке:\", round(scores_svm_model.mean(),2))\n",
    "print(\"Средняя точность модели svm_model_scaled с использованием стандартизации на перекрестной проверке:\", round(scores_svm_model_scaled.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** SVM-модель показывает одинаковую среднюю точность при кросс-валидации как со стандартизированными, так и с нестандартизированными данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Поиск наилучшего значения kernel для SVM-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parametres: linear\n"
     ]
    }
   ],
   "source": [
    "param_grid_svm = {'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "grid_search_svm = GridSearchCV(svm_model_scaled,param_grid_svm, cv=5)\n",
    "grid_search_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Best parametres:', grid_search_svm.best_params_['kernel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Метод kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва кратко опишем суть метода собственным словами. Допустим, что нам необходимо провести классификацию объектов на два класса — красный или желтый. Нам дана некоторая обучающая выборка и целевой объект (серого цвета):\n",
    "\n",
    "<img src='knn.png' width=900, heigth=240>\n",
    "\n",
    "Необходимо определить, к какому классу относится серый объект.\n",
    "\n",
    "Интуитивно мы видим, что поскольку все его соседи желтые, то и он сам должен быть желтым. Эта интуиция и отражает суть метода kNN — классифицировать целевой объект, основаваясь на том, к каким классам относятся объекты, максимально похожие на него.\n",
    "\n",
    "**Вот основные шаги метода kNN:**\n",
    "\n",
    "1. **Выбор числа соседей (k):** Это гиперпараметр, который определяет количество ближайших соседей, учитываемых при классификации или регрессии. Выбор значения k зависит от конкретной задачи и может влиять на качество модели.\n",
    "\n",
    "2. **Вычисление расстояний:** Для каждого тестового объекта вычисляются расстояния до всех обучающих объектов в пространстве признаков. Расстояние обычно измеряется с использованием метрики, такой как евклидово расстояние, манхэттенское расстояние, косинусное расстояние и т. д.\n",
    "\n",
    "3. **Собственно нахождение k ближайших соседей:** Выбираются k объектов обучающего набора, ближайших к тестовому объекту в соответствии с расстояниями.\n",
    "\n",
    "4. **Определение класса (или значения) объекта:** Для задачи классификации, класс тестового объекта определяется путем голосования: объект относится к тому классу, который преобладает среди его k ближайших соседей. Для задачи регрессии, значение тестового объекта может быть определено как среднее (или взвешенное среднее) значений его k ближайших соседей.\n",
    "\n",
    "5. **Оценка качества модели:** После классификации или регрессии всех тестовых объектов можно оценить качество модели с использованием метрик, таких как точность, F1-мера, среднеквадратическая ошибка и т. д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку нам необходимо найти оптимальные значения k, которое является ничем иным, как гиперпараметром, то для этого нужно воспользовать поиском по сетке методом кросс-валидации.\n",
    "\n",
    "Если бы оптимальное значение искать было не нужно, то и поиск по сетке мы бы не делали!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отптимальное значение k: 9\n",
      "Accuracy kNN с оптимальным k: 0.75\n"
     ]
    }
   ],
   "source": [
    "#Определяем оптимальные значения k\n",
    "param_grid_knn = {'n_neighbors': range(1,11)} #Опробуем значения k от 1 до 10\n",
    "knn_model = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(knn_model, param_grid_knn, cv=5)\n",
    "grid_search_knn.fit(X_train_scaled, y_train)\n",
    "best_k = grid_search_knn.best_params_['n_neighbors']\n",
    "\n",
    "#Обучение модели kNN с оптимальным значением k\n",
    "knn_model_optimal = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_model_optimal.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Оцениваем качество модели\n",
    "y_pred_knn = knn_model_optimal.predict(X_test_scaled)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print('Отптимальное значение k:', best_k)\n",
    "print('Accuracy kNN с оптимальным k:', round(accuracy_knn,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть задано некоторое бинарное дерево, в котором:\n",
    "\n",
    "- каждой внутренней вершине $v$ приписан предикат $B_v: \\mathbb{X} \\rightarrow 0,1$;\n",
    "\n",
    "- каждой листовой вершине $v$ припсано предсказание $c_v \\in \\mathbb{Y}$, где $\\mathbb{Y}$ — область значений целевой переменной.\n",
    "\n",
    "В ходе каждого предсказания происходит проход по этому дереву от корня к некоторому листу. В очередной внутренней вершине $v$ проход продолжится вправо, если $B_v(x) = 1$, или влево, если $B_v(x)=0$. Проход продолжится до момента, пока не будет достигнут некоторый лист. Ответом алгоритма на объекте $x$ считается предсказание $c_v$, приписанное этому листу.\n",
    "\n",
    "В предикатах обычно используют сравнение с некоторым порогом $t \\in \\mathbb{R}$ по какому-то $j$-му признаку: $$B_v(x,j,t) = [x_j \\leq t].$$\n",
    "\n",
    "Из структуры дерева решений следуют определенный интресные свойства:\n",
    "\n",
    "- выученная функция является кусочно-постоянной, а значит производная равна нулю на всей области определения. Таким образом, о градиентных методах можно даже и не думать;\n",
    "\n",
    "- чтобы результат обладал хорошей обобщающей способностью (то есть мог что-то выучить), нам необходимо оставлять дерево как можно более простым;\n",
    "\n",
    "- дерево решений (в отличие от линейной модели) не сможет экстраполировать зависимости за границы области значений обучающей выборки.\n",
    "\n",
    "Так же следует отметить, что решаюшие деревья имеют низкую обобщающую способность, но поскольку они достаточно легки в построении, их часто используют как кирпичики в построении ансамблей — моделей, предсказания которых делаются на основе агрегации предсказаний других моделей.\n",
    "\n",
    "Ниже на картинке слева представлен пример решающего дерева, а справа представлен пример соответствующей решаюшей поверхности, порождаемой дерево:\n",
    "\n",
    "<img src='decTreeAndPlane.png' width=900, heigth=240>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность (accuracy) модели дерева решений: 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "dt_accuracy = accuracy_score(y_test, dt_model.predict(X_test_scaled))\n",
    "print('Точность (accuracy) модели дерева решений:', round(dt_accuracy,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Оценка качества дерева решений и kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Classification Report для дерева решений:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76        53\n",
      "           1       0.50      0.62      0.56        24\n",
      "\n",
      "    accuracy                           0.69        77\n",
      "   macro avg       0.65      0.67      0.66        77\n",
      "weighted avg       0.71      0.69      0.70        77\n",
      "\n",
      "- Classification Report для kNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        53\n",
      "           1       0.63      0.50      0.56        24\n",
      "\n",
      "    accuracy                           0.75        77\n",
      "   macro avg       0.71      0.68      0.69        77\n",
      "weighted avg       0.74      0.75      0.74        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_decTr = dt_model.predict(X_test_scaled)\n",
    "print('- Classification Report для дерева решений:')\n",
    "print(classification_report(y_test, y_pred_decTr))\n",
    "\n",
    "y_pred_knn = knn_model_optimal.predict(X_test_scaled)\n",
    "print('- Classification Report для kNN:')\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Оптимальное значение гиперпараметра max_depth через поиск по сетке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметр max_depth (по-сути, максимальная глубина) является одним из важнейших параметров для регуляризации и контроля переобучения в построении деревьев решений и их ансамблей. В дереве решений, глубина дерева определяет, сколько раз дерево делит данные. Чем больше глубина — тем сложнее модель и тем больше вероятность переобучения. \n",
    "\n",
    "Гиперпараметр max-depth ограничивает максимальную глубину дерева, что позволяет контролировать его сложность и предотвращать переобучение модели.\n",
    "\n",
    "Выбор оптимального значения max_depth зависит от конкретного набора данных и требует настройки при помощи кросс-валидации или других методов оценки моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальное значение max_depth: 3\n",
      "Оптимальное значение качества модели: 0.63\n"
     ]
    }
   ],
   "source": [
    "param_grid_md = {'max_depth': [3, 5, 7, 9, None]}\n",
    "\n",
    "grid_search_md = GridSearchCV(estimator=dt_model, param_grid=param_grid_md, cv=5)\n",
    "grid_search_md.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Оптимальное значение max_depth:', grid_search_md.best_params_['max_depth']) #Чтобы выводилось само значение, а не словарь, указываем это в квадратных скобках\n",
    "print('Оптимальное значение качества модели:', round(grid_search.best_score_,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Обучим модель дерева решений с оптимальным max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88        53\n",
      "           1       0.76      0.67      0.71        24\n",
      "\n",
      "    accuracy                           0.83        77\n",
      "   macro avg       0.81      0.79      0.80        77\n",
      "weighted avg       0.83      0.83      0.83        77\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimal_max_depth = grid_search_md.best_params_['max_depth']\n",
    "optimal_dt_model = DecisionTreeClassifier(max_depth=optimal_max_depth)\n",
    "\n",
    "optimal_dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_opt_dt_model = optimal_dt_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred_opt_dt_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь нужно сделать важное примечание. Чем отличается оценка, произведенная сразу после нахождения оптимального значения max_depth и новая, проведенная в этом разделе?\n",
    "\n",
    "Первая оценка использует кросс-валидацию. Она оценивает модель на нескольких разбиениях обучающего набора анных, а затем усредняет показатели качества по всем фолдам. Такая оценка позволяет оценить обобшщающую способность модели и сделать выводы о ее эффективности на новых данных.\n",
    "\n",
    "Вторая оценка производится уже на всем обучающем наборе данных с использованием найденного оптимального значения гиперпараметра. Она производится на отложенном тестовом наборе данных. Этот подход позволяет оценить производительность модели на реальных данных, которые она ранее не видела."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Сравним все полученные модели и сделаем выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрик выберем следующие: accuracy, recall, f1, ROC-AUC. \n",
    "\n",
    "В совокупности мы имеем 7 моделей:\n",
    "1. Модель логистической регрессии с нестандартизированными параметрами\n",
    "2. Модель логистической регрессии со стандартизированными параметрами\n",
    "3. SVM-модель с нестандартизированными параметрами\n",
    "4. SVM-модель со стандартизированными параметрами\n",
    "5. kNN\n",
    "6. Дерево решений\n",
    "7. Дерево решений с оптимальным max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Оценка модели логистической регрессии с нестандартизированными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86        53\n",
      "           1       0.71      0.62      0.67        24\n",
      "\n",
      "    accuracy                           0.81        77\n",
      "   macro avg       0.78      0.76      0.76        77\n",
      "weighted avg       0.80      0.81      0.80        77\n",
      "\n",
      "AUC-ROC: 0.89\n"
     ]
    }
   ],
   "source": [
    "print('Classification report:\\n', class_report)\n",
    "y_proba = lr_model.predict_proba(X_test)[:, 1]\n",
    "print('AUC-ROC:', round(roc_auc_score(y_test, y_proba),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.81\n",
    "\n",
    "Recall (1): 0.62\n",
    "\n",
    "f1-score (1): 0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Оценка модели логистической регрессии со стандартизированными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87        53\n",
      "           1       0.75      0.62      0.68        24\n",
      "\n",
      "    accuracy                           0.82        77\n",
      "   macro avg       0.80      0.77      0.78        77\n",
      "weighted avg       0.81      0.82      0.81        77\n",
      "\n",
      "AUC-ROC: 0.9\n"
     ]
    }
   ],
   "source": [
    "print('Classification report:\\n', class_report_scaled)\n",
    "y_proba_scaled = lr_model_scaled.predict_proba(X_test_scaled)[:, 1]\n",
    "print('AUC-ROC:', round(roc_auc_score(y_test, y_proba_scaled),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.82\n",
    "\n",
    "Recall (1): 0.62\n",
    "\n",
    "f1-score (1): 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.3. Оценка SVM-модели с нестандартизированными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85        53\n",
      "           1       0.70      0.58      0.64        24\n",
      "\n",
      "    accuracy                           0.79        77\n",
      "   macro avg       0.76      0.74      0.75        77\n",
      "weighted avg       0.79      0.79      0.79        77\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, classification_report(y_test, y_pred_svm))\n\u001b[0;32m----> 2\u001b[0m y_proba_svm \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC-ROC:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mround\u001b[39m(roc_auc_score(y_test, y_proba_svm),\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     26\u001b[0m attr_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(owner\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattribute_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck(obj):\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attr_err\n\u001b[1;32m     34\u001b[0m     out \u001b[38;5;241m=\u001b[39m MethodType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn, obj)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:829\u001b[0m, in \u001b[0;36mBaseSVC._check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability:\n\u001b[0;32m--> 829\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    830\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba is not available when  probability=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m         )\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnu_svc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba only implemented for SVC and NuSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "print('Classification report:\\n', classification_report(y_test, y_pred_svm))\n",
    "y_proba_svm = svm_model.predict_proba(X_test)[:, 1]\n",
    "print('AUC-ROC:', round(roc_auc_score(y_test, y_proba_svm),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
